{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFg0q5Uxfr3a"
   },
   "source": [
    "# GR5242 HW01 Problem 1: Basics\n",
    "\n",
    "**Instructions**: This problem is an individual assignment -- you are to complete this problem on your own, without conferring with your classmates.  You should submit a completed and published notebook to Courseworks; no other files will be accepted.\n",
    "\n",
    "**Description**: The goal of this problem is to get your familiar with neural network training from end to end.\n",
    "\n",
    "Our main tool is `torch`, especially [`torch.nn`](https://pytorch.org/docs/stable/nn.html) and [`torch.optim`](https://pytorch.org/docs/stable/optim.html), that helps us with model building and automatic differentiation / backpropagation.\n",
    "\n",
    "There are 4 questions in this notebook, including 3 coding quesitons and 1 text question. Each coding question expects 1~3 lines of codes, and the text question expects just 1 sentence of explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbF3-OFyFTG_",
    "outputId": "d281e3a4-5a0b-448a-f7e9-9992e28db9b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch imports:\n",
    "#\n",
    "# torch is the base package, nn gives nice classes for Neural Networks,\n",
    "# F contains our ReLU function, optim gives our SG method,\n",
    "# DataLoader allows us to do batches efficiently,\n",
    "# and torchvision is for downloading MNIST data directly from PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lxOoXP0jDLr"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "We will working on `mnist` dataset, which contain images of written digits of 0-9 and corresponding labels.\n",
    "\n",
    "We have it set up to download the data directly from the `torch` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjY9zAOOhIQo",
    "outputId": "c55bf22b-3e66-4277-ea71-b9bc937ca039",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, we will define a way of transforming the dataset automatically\n",
    "# upon downloading from pytorch\n",
    "\n",
    "# first convert an image to a tensor and then scale its values to be between -1 and 1, which can be beneficial for training certain neural networks\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "# Next, we fetch the data\n",
    "\n",
    "mnist_train = datasets.MNIST(root='./data', train=True,\n",
    "                             download=True, transform=transform)\n",
    "mnist_test  = datasets.MNIST(root='./data', train=False,\n",
    "                             download=True, transform=transform)\n",
    "\n",
    "# and define our DataLoaders\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(mnist_test,  batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U12vhTEAjVEh"
   },
   "source": [
    "Each image is represented as a 28x28 matrix of pixel values, and each label is the corresponding digit.\n",
    "\n",
    "Let's show an image of a random one! Try running the below cell a few times to see different examples and how the DataLoaders will be shuffling batches.\n",
    "\n",
    "Note: Why is this random, when there is no random code in the next cell? The randomness comes from `shuffle=True` in the `train_loader`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "upY8cssFhkbU",
    "outputId": "fc70b491-5c3a-4547-c1aa-e59898ef6de3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "plt.imshow(inputs[23].squeeze())\n",
    "plt.title('Training label: '+str(classes[23].item()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vklyKbJGktZW"
   },
   "source": [
    "Let's now show 25 of them in black and white:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "id": "al111BTQkmUf",
    "outputId": "95d56e7b-b8dd-44dc-877d-9d6efc43158f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(inputs[i].squeeze(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(classes[i].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8fu-vrLM6P9"
   },
   "source": [
    "By printing out the shapes, we see there are 60,000 training data and 10,000 test data. Each image is represented as a 28x28 matrix of pixel values, and each label is the corresponding digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pktzl2TqMy7u",
    "outputId": "549df4c9-7b13-45d8-d26c-eacc73fdc2cc"
   },
   "outputs": [],
   "source": [
    "# For training data\n",
    "train_data_example, train_label_example = mnist_train[0]\n",
    "print(\"Shape of a single training image:\", train_data_example.shape)\n",
    "\n",
    "# For test data\n",
    "test_data_example, test_label_example = mnist_test[0]\n",
    "print(\"Shape of a single test image:\", test_data_example.shape)\n",
    "\n",
    "# The total number of images in each dataset\n",
    "print(\"Total number of training images:\", len(mnist_train))\n",
    "print(\"Total number of test images:\", len(mnist_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1p2zp4ZmAOC"
   },
   "source": [
    "## Recap of classification task\n",
    "\n",
    "In a classification task with $K$ classes, suppose the predicted logits for an image are $s_1, \\cdots, s_K$. The predicted probabilities are then\n",
    "\n",
    "$$\\hat p_i = \\frac{\\exp \\{ s_i\\}}{\\sum_{j=1}^K \\exp \\{s_j\\}}, \\text{ for }i=1:K$$\n",
    "\n",
    "The CrossEntropy (CE) loss is defined as\n",
    "\n",
    "$$CE = - \\sum_{i=1}^K t_i \\log (\\hat p_i)$$\n",
    "\n",
    "where $t_i=1$ if the image belongs to the $i$th class or otherwise $t_i=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYSHF9pSm5uB"
   },
   "source": [
    "## Model\n",
    "\n",
    "Now, we will build a model to predict the logits of images for the classificaiton task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMdSR9k9FTHE"
   },
   "source": [
    "### Question 1: Building the Model\n",
    "\n",
    "In the following, we will write a class for a basic one-hidden-layer, ReLU, feedforward network. There are a few components to a model in Pytorch, and we will break them down step by step.\n",
    "\n",
    "First, we need to define the class. As with any class definition, we start with an `__init__` method. Since Pytorch provides us with many useful features within the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class, we will use inheritence to pass these down to our `Net` class. This involves putting nn.Module inside the parenthesis in the class definition, and a `super().__init__()` call in the `__init__()` method.\n",
    "\n",
    "Within the initialization, we then define two layers: one hidden layer with 128 neurons, and one output layer with `10` class logits. The hidden layer should take an input of size `28 x 28` and give an output of size `128`, while the output layer takes input of size `128` and gives output of size `10`. It is suggested to use the [`nn.Linear()`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) object to accomplish this, which applies a transformation $z = x W^T + b$.\n",
    "\n",
    "Next, we define a special method called `forward(),` which defines how data propagate through the model. This method will be called either by `model.forward(x)` or by `model(x)`, and is where Pytorch looks for the information for its automatic derivative computation capabilities.\n",
    "\n",
    "In the forward method, we first will reshape our image `img` using `img.view()`.\n",
    "\n",
    "Then, we will apply the hidden layer (the one we defined) and the ReLU function `F.relu`.\n",
    "\n",
    "Finally, we apply the output layer and return our output. Importantly, do not apply SoftMax to the output just yet. We will handle that part later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRvcSYInFTHF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ### YOUR CODE HERE ###\n",
    "        # define hidden layer and output layer below:\n",
    "\n",
    "        \n",
    "        \n",
    "        ######################\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28) # reshape the image to be a single row\n",
    "        # pass x through both layers, with ReLU in between\n",
    "        ### YOUR CODE HERE ###\n",
    "\n",
    "        \n",
    "        \n",
    "        ######################\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3V7Haucmwu1"
   },
   "source": [
    "### Question 2: Defining the Loss and Optimizer\n",
    "\n",
    "When training a `torch` model, typically you need to specify the following two items:\n",
    "\n",
    "- optimizer: specifies a way to apply gradient descent update of model parameters. We will use the [`optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer with a learning rate of 0.001 in this example.\n",
    "\n",
    "- loss_fn: the objective function to minimize over. In classification task, the cross-entropy loss is used.\n",
    "\n",
    "Please fill in the `optimizer` with an appropriate learning rate `lr`, and choose an appropriate number of `epochs` (number of passes through the data) in the following code.\n",
    "\n",
    "Note: remember that the neural network outputs the `logits` instead of the class probabilities (why? answer the question below), and make sure to specify this in the `loss function`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5qqPdbQFTHF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "######################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tohEZ0q7uUl"
   },
   "source": [
    "### Question 3: The neural network specified above does not output class probabilities, because the last layer of the neural network is a linear layer which outputs value ranging from $(-\\infty, \\infty)$.  Your choice of loss function above should take care of that, but what _mathematical_ function maps these logit values to class probabilities?\n",
    "\n",
    "#######################\n",
    "###### YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-H7Wca-nakt"
   },
   "source": [
    "## Training\n",
    "\n",
    "Now let's train the model for your chosen number of epochs. By the end of the training, you should expect an accuracy above 0.98.\n",
    "\n",
    "In each step, we need to:\n",
    "\n",
    "1.) grab `x` and `y` from the batch (note that each batch is a tuple of `x` and `y`)\n",
    "\n",
    "2.) zero the optimizer's gradients\n",
    "\n",
    "3.) make a prediction `y_pred`\n",
    "\n",
    "4.) call the `loss_fn` between `y` and `y_pred`\n",
    "\n",
    "5.) backpropagate\n",
    "\n",
    "6.) make the approprite step calculated by the `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCsIvUUVlEAA",
    "outputId": "13c4e583-a095-4e40-d9d2-a7107dbddb28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    for batch in train_loader:\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        x_batch, y_batch = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ### YOUR CODE HERE ###\n",
    "        \n",
    "        ######################\n",
    "        \n",
    "        for index, output in enumerate(y_logit):\n",
    "            y_pred = torch.argmax(output)\n",
    "            if y_pred == y_batch[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        ### YOUR CODE HERE ###\n",
    "        \n",
    "        ######################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(correct/total)\n",
    "\n",
    "    avg_loss     = np.mean(np.array(losses))\n",
    "    avg_accuracy = np.mean(np.array(accuracies))\n",
    "    print('epoch ' + str(epoch+1) + ' average loss: ', avg_loss,\n",
    "          '-- average accuracy: ', avg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez2L6AmplHtE"
   },
   "source": [
    "## Test Evaluation\n",
    "\n",
    "Finally, we evaluate our model on the test set. You could expect the test accuracy to be slightly lower than the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obLm4idVlIQx",
    "outputId": "57d2e2e1-b9c1-40a5-8439-e8dbadcdd283"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        y_logit = model(x_batch)\n",
    "        for index, output in enumerate(y_logit):\n",
    "            y_pred = torch.argmax(output)\n",
    "            if y_pred == y_batch[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('testing accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vta0K8K68-BV"
   },
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN3zdNTU_SPe"
   },
   "source": [
    "#### Question 4: fill in the following code block to estimate class probabilities and make predictions on test images. The results should be stored in `class_probabilities` and `predicted_labels`. Compare to the true labels, stored in `true_labels` by computing the accuracy. It should be the same as above.\n",
    "\n",
    "#### (Hint: you can use much of the same structure from the cell above. You can use `F.softmax` to calculate probabilities from the logits, and store the results however you please.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZeBzWcLQVFA",
    "outputId": "1ce84140-ee4a-45a9-dc42-7427b6dc7629"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "print('accuracy verification: ', sum(true_labels==predicted_labels)/len(true_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
